{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d7876e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c33e21b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    \"image_dir\": \"sleepy/dataset/Trainning/image_trainning/all_image_trainning\",\n",
    "    \"label_dir\": \"sleepy/dataset/Trainning/label_trainning/all_label_trainning\",\n",
    "    \"test_image_dir\": \"sleepy/dataset/Test/image_test/all_image_test\",\n",
    "    \"test_label_dir\": \"sleepy/dataset/Test/label_test/all_label_test\",\n",
    "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    \"img_size\": 90,\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 5,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"max_samples\": 15000,\n",
    "    \"model_path\": \"eye_state_classifier.pth\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53ce4aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2bool(val: str) -> bool:\n",
    "    return str(val).strip().lower() == \"true\"\n",
    "\n",
    "def crop_and_resize_eye(frame: np.ndarray, bbox: tuple, size: int = 90) -> np.ndarray | None:\n",
    "    if bbox is None:\n",
    "        return None\n",
    "    x, y, w, h = bbox\n",
    "    x1 = max(x - int(w * 0.5), 0)\n",
    "    y1 = max(y - int(h * 0.5), 0)\n",
    "    x2 = min(x + w + int(w * 0.5), frame.shape[1])\n",
    "    y2 = min(y + h + int(h * 0.5), frame.shape[0])\n",
    "    eye_crop = frame[y1:y2, x1:x2]\n",
    "    if eye_crop.size == 0:\n",
    "        return None\n",
    "    return cv2.resize(eye_crop, (size, size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06867e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EyeDataset(Dataset):\n",
    "    def __init__(self, image_dir, label_dir, transform=None, max_samples=None):\n",
    "        self.image_dir = Path(image_dir)\n",
    "        self.label_dir = Path(label_dir)\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "\n",
    "        image_files = sorted([f for f in os.listdir(image_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "        if max_samples:\n",
    "            image_files = image_files[:max_samples]\n",
    "\n",
    "        print(\"🔍 유효한 눈 데이터를 수집 중...\")\n",
    "        for img_name in tqdm(image_files):\n",
    "            img_path = self.image_dir / img_name\n",
    "            label_path = self.label_dir / (img_name.rsplit('.', 1)[0] + '.json')\n",
    "            if not label_path.exists():\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                with open(label_path, 'r', encoding='utf-8') as f:\n",
    "                    label_data = json.load(f)\n",
    "            except Exception:\n",
    "                continue\n",
    "            \n",
    "            object_info = label_data.get('ObjectInfo', {})\n",
    "            bounding_boxes = object_info.get('BoundingBox', {})\n",
    "            \n",
    "            leye_info = bounding_boxes.get('Leye', {})\n",
    "            reye_info = bounding_boxes.get('Reye', {})\n",
    "\n",
    "            if not (leye_info.get('isVisible', False) and reye_info.get('isVisible', False)):\n",
    "                continue\n",
    "\n",
    "            leye_opened = str2bool(leye_info.get('Opened', 'false'))\n",
    "            reye_opened = str2bool(reye_info.get('Opened', 'false'))\n",
    "\n",
    "            leye_pos = leye_info.get('Position', [0, 0, 0, 0])\n",
    "            reye_pos = reye_info.get('Position', [0, 0, 0, 0])\n",
    "            \n",
    "            try:\n",
    "                leye_bbox = tuple(map(int, map(float, leye_pos)))\n",
    "                reye_bbox = tuple(map(int, map(float, reye_pos)))\n",
    "            except (ValueError, TypeError):\n",
    "                continue\n",
    "\n",
    "            if leye_bbox[2] > 0 and leye_bbox[3] > 0:\n",
    "                self.samples.append((str(img_path), leye_bbox, int(leye_opened)))\n",
    "            if reye_bbox[2] > 0 and reye_bbox[3] > 0:\n",
    "                self.samples.append((str(img_path), reye_bbox, int(reye_opened)))\n",
    "            \n",
    "        print(f\"✅ 총 {len(self.samples)}개의 눈 이미지 수집 완료\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, bbox, label = self.samples[idx]\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"경고: 파일을 찾을 수 없습니다: {img_path}\")\n",
    "            return None, None\n",
    "\n",
    "        x, y, w, h = bbox\n",
    "        if w <= 0 or h <= 0:\n",
    "            return None, None\n",
    "        \n",
    "        eye_img = image.crop((x, y, x + w, y + h))\n",
    "\n",
    "        if self.transform:\n",
    "            eye_img = self.transform(eye_img)\n",
    "\n",
    "        return eye_img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7879727e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EyeCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 5 * 5, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        # Flatten 후 FC 레이어에 맞는 크기로 reshape\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # EyeCNN 모델의 fc 레이어 크기가 128 * 5 * 5로 하드코딩 되어있어\n",
    "        # 입력 이미지 크기가 90이 아닐 경우 에러가 발생할 수 있습니다.\n",
    "        # MaxPool2d를 4번 거친 후 크기는 90 -> 45 -> 22 -> 11 -> 5 가 됩니다.\n",
    "        # 따라서 Flatten 후 128 * 5 * 5가 됩니다.\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4379f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 유효한 눈 데이터를 수집 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13446/13446 [00:01<00:00, 7139.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 총 6960개의 눈 이미지 수집 완료\n",
      "🔍 유효한 눈 데이터를 수집 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 510/510 [00:00<00:00, 5994.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 총 20개의 눈 이미지 수집 완료\n",
      "\n",
      "학습 샘플 수: 6960\n",
      "테스트 샘플 수: 20\n",
      "\n",
      "=== 🚀 학습 시작 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 218/218 [00:58<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 | Loss: 0.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  64%|██████▍   | 140/218 [00:39<00:23,  3.37it/s]"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, device, epochs):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    print(\"\\n=== 🚀 학습 시작 ===\")\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            if images.nelement() == 0:\n",
    "                continue\n",
    "            images = images.to(device)\n",
    "            labels = labels.float().unsqueeze(1).to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        if len(train_loader) > 0:\n",
    "            avg_loss = total_loss / len(train_loader)\n",
    "            print(f\"Epoch {epoch+1}/{epochs} | Loss: {avg_loss:.4f}\")\n",
    "            losses.append(avg_loss)\n",
    "        else:\n",
    "            print(f\"Epoch {epoch+1}/{epochs} | 학습할 데이터가 없습니다.\")\n",
    "\n",
    "    return losses\n",
    "\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    preds, trues = [], []\n",
    "    print(\"\\n=== 📊 테스트 평가 시작 ===\")\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc=\"평가 중\"):\n",
    "            if images.nelement() == 0:\n",
    "                continue\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            predicted = (outputs > 0.5).int().cpu()\n",
    "            preds.append(predicted)\n",
    "            trues.append(labels.cpu())\n",
    "\n",
    "    if not preds:\n",
    "        print(\"❗ 예측 결과가 없습니다. 테스트 데이터셋을 확인해주세요.\")\n",
    "        return np.array([]), np.array([])\n",
    "    \n",
    "    y_pred = torch.cat(preds).view(-1).numpy()\n",
    "    y_true = torch.cat(trues).view(-1).numpy()\n",
    "    \n",
    "    return y_true, y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c36cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # 데이터 변환 정의\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((CONFIG['img_size'], CONFIG['img_size'])),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    # 데이터셋 및 데이터로더 준비\n",
    "    train_dataset = EyeDataset(CONFIG['image_dir'], CONFIG['label_dir'], transform=transform, max_samples=CONFIG['max_samples'])\n",
    "    test_dataset = EyeDataset(CONFIG['test_image_dir'], CONFIG['test_label_dir'], transform=transform)\n",
    "\n",
    "    def collate_fn(batch):\n",
    "        batch = list(filter(lambda x: x[0] is not None, batch))\n",
    "        if not batch:\n",
    "            return torch.Tensor(), torch.Tensor()\n",
    "        return torch.utils.data.dataloader.default_collate(batch)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=CONFIG['batch_size'], shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    print(f\"\\n학습 샘플 수: {len(train_dataset)}\")\n",
    "    print(f\"테스트 샘플 수: {len(test_dataset)}\")\n",
    "\n",
    "    # 모델, 손실 함수, 옵티마이저 정의\n",
    "    model = EyeCNN().to(CONFIG['device'])\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=CONFIG['learning_rate'])\n",
    "\n",
    "    # 모델 학습\n",
    "    losses = train_model(model, train_loader, criterion, optimizer, CONFIG['device'], CONFIG['epochs'])\n",
    "\n",
    "    # 학습된 모델 저장\n",
    "    torch.save(model.state_dict(), CONFIG['model_path'])\n",
    "    print(f\"\\n✅ 모델이 '{CONFIG['model_path']}'에 저장되었습니다.\")\n",
    "\n",
    "    # 모델 평가\n",
    "    # (선택 사항) 저장된 모델을 다시 로드하여 평가할 수도 있습니다.\n",
    "    # model.load_state_dict(torch.load(CONFIG['model_path']))\n",
    "    y_true, y_pred = evaluate_model(model, test_loader, CONFIG['device'])\n",
    "    \n",
    "    # 평가 결과 출력\n",
    "    if len(y_true) > 0:\n",
    "        print(\"\\n[ 최종 평가 결과 ]\")\n",
    "        print(classification_report(y_true, y_pred, target_names=[\"Closed (0)\", \"Opened (1)\"], zero_division=0))\n",
    "        \n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(confusion_matrix(y_true, y_pred))\n",
    "        \n",
    "        print(f\"\\nAccuracy: {accuracy_score(y_true, y_pred):.4f}\")\n",
    "    \n",
    "    # 손실 그래프 시각화\n",
    "    if losses:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(losses, label='Train Loss')\n",
    "        plt.title(\"Training Loss per Epoch\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
