{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "764639db-0fab-459f-af83-4e00ca318f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\anaconda3\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: torchvision in c:\\anaconda3\\lib\\site-packages (0.22.1)\n",
      "Requirement already satisfied: torchaudio in c:\\anaconda3\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: lightning in c:\\anaconda3\\lib\\site-packages (2.5.2)\n",
      "Requirement already satisfied: filelock in c:\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\anaconda3\\lib\\site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\anaconda3\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: numpy in c:\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\anaconda3\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: PyYAML<8.0,>=5.4 in c:\\anaconda3\\lib\\site-packages (from lightning) (6.0.1)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in c:\\anaconda3\\lib\\site-packages (from lightning) (0.14.3)\n",
      "Requirement already satisfied: packaging<27.0,>=20.0 in c:\\anaconda3\\lib\\site-packages (from lightning) (24.1)\n",
      "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in c:\\anaconda3\\lib\\site-packages (from lightning) (1.7.4)\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in c:\\anaconda3\\lib\\site-packages (from lightning) (4.66.5)\n",
      "Requirement already satisfied: pytorch-lightning in c:\\anaconda3\\lib\\site-packages (from lightning) (2.5.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\anaconda3\\lib\\site-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning) (3.10.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\anaconda3\\lib\\site-packages (from tqdm<6.0,>=4.57.0->lightning) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (1.11.0)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\anaconda3\\lib\\site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning) (3.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a05259db-19e6-4b4c-9676-73361df2a832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "a = 1\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "791b0cba-7f6e-4db1-ae31-4cdb23f93dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "웹캠 실행 중... 's' 키를 누르면 눈을 저장하고, 'q' 키를 누르면 종료됩니다.\n",
      "종료합니다.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "SAVE_DIR = r\"C:\\Users\\Users\\eye_captures\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "# Mediapipe 초기 설정\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    refine_landmarks=True,\n",
    "    max_num_faces=1,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# 눈 랜드마크 인덱스 (정확한 좌우 기준)\n",
    "RIGHT_EYE_IDX = [33, 133, 160, 159, 158, 157, 173, 246]   # 사람의 오른쪽 눈 (화면에서는 왼쪽)\n",
    "LEFT_EYE_IDX = [362, 263, 387, 386, 385, 384, 398, 466]   # 사람의 왼쪽 눈 (화면에서는 오른쪽)\n",
    "\n",
    "\n",
    "\n",
    "# 눈 이미지 추출 함수\n",
    "def extract_eye(image, landmarks, eye_indices, padding=20):\n",
    "    ih, iw, _ = image.shape\n",
    "    eye_points = np.array([(int(landmarks[i].x * iw), int(landmarks[i].y * ih)) for i in eye_indices])\n",
    "    x, y, w, h = cv2.boundingRect(eye_points)\n",
    "\n",
    "    x = max(x - padding, 0)\n",
    "    y = max(y - padding, 0)\n",
    "    w = min(w + padding * 2, iw - x)\n",
    "    h = min(h + padding * 2, ih - y)\n",
    "\n",
    "    eye_img = image[y:y+h, x:x+w]\n",
    "    return eye_img\n",
    "\n",
    "# 웹캠 시작\n",
    "cap = cv2.VideoCapture(0)\n",
    "print(\"웹캠 실행 중... 's' 키를 누르면 눈을 저장하고, 'q' 키를 누르면 종료됩니다.\")\n",
    "\n",
    "left_eye_img = None\n",
    "right_eye_img = None\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        print(\"카메라 프레임을 가져올 수 없습니다.\")\n",
    "        break\n",
    "\n",
    "    # RGB 변환\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb_frame)\n",
    "\n",
    "    # 눈 영역 추출\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            landmarks = face_landmarks.landmark\n",
    "            try:\n",
    "                left_eye_img = extract_eye(frame, landmarks, LEFT_EYE_IDX)\n",
    "                right_eye_img = extract_eye(frame, landmarks, RIGHT_EYE_IDX)\n",
    "\n",
    "                # 눈 이미지 실시간 출력\n",
    "                if left_eye_img.size > 0:\n",
    "                    cv2.imshow(\"Left Eye\", left_eye_img)\n",
    "                if right_eye_img.size > 0:\n",
    "                    cv2.imshow(\"Right Eye\", right_eye_img)\n",
    "            except Exception as e:\n",
    "                print(\"눈 추출 중 오류 발생:\", e)\n",
    "                continue\n",
    "\n",
    "    # 원본 영상 표시\n",
    "    cv2.imshow(\"Webcam\", frame)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    # 눈 저장: 's' 키\n",
    "    if key == ord('s') and left_eye_img is not None and right_eye_img is not None:\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S%f\")\n",
    "        left_path = f\"left_eye_{timestamp}.png\"\n",
    "        right_path = f\"right_eye_{timestamp}.png\"\n",
    "\n",
    "        # ✅ 눈 이미지 90x90으로 리사이즈\n",
    "        left_resized = cv2.resize(left_eye_img, (90, 90))\n",
    "        right_resized = cv2.resize(right_eye_img, (90, 90))\n",
    "\n",
    "        # ✅ 저장\n",
    "        cv2.imwrite(os.path.join(SAVE_DIR, left_path), left_resized)\n",
    "        cv2.imwrite(os.path.join(SAVE_DIR, right_path), right_resized)\n",
    "\n",
    "        print(f\"눈 저장 완료: {left_path}, {right_path}\")\n",
    "\n",
    "    # 종료: 'q' 키\n",
    "    elif key == ord('q'):\n",
    "        print(\"종료합니다.\")\n",
    "        break\n",
    "\n",
    "# 종료 처리\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "583f6bc3-1751-406e-8055-9117e0e3d14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 작업 디렉토리: C:\\Windows\\System32\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"현재 작업 디렉토리:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46a17e1f-5742-4d15-9433-aba30c9ff1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train/open] 이미지 1000장 처리 중...\n",
      "[train/closed] 이미지 1000장 처리 중...\n",
      "[val/open] 이미지 1000장 처리 중...\n",
      "[val/closed] 이미지 1000장 처리 중...\n",
      "[test/open] 이미지 1000장 처리 중...\n",
      "[test/closed] 이미지 1000장 처리 중...\n",
      "\n",
      "📊 예측 결과 요약\n",
      "총 이미지 수     : 6000\n",
      "정확히 예측한 수 : 3364\n",
      "정확도           : 56.07%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Mediapipe 설정\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    static_image_mode=True,\n",
    "    refine_landmarks=True,\n",
    "    max_num_faces=1,\n",
    "    min_detection_confidence=0.5\n",
    ")\n",
    "\n",
    "# 눈 감김 판별 함수\n",
    "def is_eye_closed(upper_y, lower_y, threshold=3):\n",
    "    return abs(upper_y - lower_y) < threshold\n",
    "\n",
    "# 기준 경로\n",
    "BASE_PATH = r\"C:\\Users\\Users\\open-closed-eyes-dataset\"\n",
    "sets = ['train', 'val', 'test']\n",
    "labels = ['open', 'closed']\n",
    "MAX_IMAGES = 1000  # 폴더당 최대 이미지 수\n",
    "\n",
    "# 결과 저장\n",
    "results = []\n",
    "\n",
    "for subset in sets:\n",
    "    for label in labels:\n",
    "        folder_path = os.path.join(BASE_PATH, subset, label)\n",
    "        image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        image_files = random.sample(image_files, min(MAX_IMAGES, len(image_files)))  # 랜덤 선택\n",
    "\n",
    "        print(f\"[{subset}/{label}] 이미지 {len(image_files)}장 처리 중...\")\n",
    "\n",
    "        for filename in image_files:\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            image = cv2.imread(file_path)\n",
    "\n",
    "            if image is None:\n",
    "                print(f\"  - 이미지 로딩 실패: {filename}\")\n",
    "                continue\n",
    "\n",
    "            ih, iw, _ = image.shape\n",
    "            rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            results_mp = face_mesh.process(rgb)\n",
    "\n",
    "            # 기본 판정: 눈을 감은 상태\n",
    "            pred_label = \"closed\"\n",
    "\n",
    "            if results_mp.multi_face_landmarks:\n",
    "                try:\n",
    "                    landmarks = results_mp.multi_face_landmarks[0].landmark\n",
    "                    # 왼쪽 눈 (386, 374), 오른쪽 눈 (159, 145)\n",
    "                    l_top = int(landmarks[386].y * ih)\n",
    "                    l_bottom = int(landmarks[374].y * ih)\n",
    "                    r_top = int(landmarks[159].y * ih)\n",
    "                    r_bottom = int(landmarks[145].y * ih)\n",
    "\n",
    "                    left_closed = is_eye_closed(l_top, l_bottom)\n",
    "                    right_closed = is_eye_closed(r_top, r_bottom)\n",
    "\n",
    "                    pred_label = 'closed' if (left_closed and right_closed) else 'open'\n",
    "\n",
    "                except Exception as e:\n",
    "                    pred_label = 'closed'  # 에러 발생 시 감은 상태로 간주\n",
    "\n",
    "            results.append({\n",
    "                'path': file_path,\n",
    "                'true_label': label,\n",
    "                'pred_label': pred_label\n",
    "            })\n",
    "\n",
    "# 정확도 계산\n",
    "total = len(results)\n",
    "correct = sum(1 for r in results if r['true_label'] == r['pred_label'])\n",
    "accuracy = (correct / total) * 100 if total > 0 else 0\n",
    "\n",
    "print(\"\\n📊 예측 결과 요약\")\n",
    "print(f\"총 이미지 수     : {total}\")\n",
    "print(f\"정확히 예측한 수 : {correct}\")\n",
    "print(f\"정확도           : {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5c56ea63-68c8-496b-be39-2a234d898a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train/open] 500장 처리 중...\n",
      "랜드마크 인식 성공 이미지 수: 73/500\n",
      "[train/closed] 500장 처리 중...\n",
      "랜드마크 인식 성공 이미지 수: 86/500\n",
      "[val/open] 500장 처리 중...\n",
      "랜드마크 인식 성공 이미지 수: 172/500\n",
      "[val/closed] 500장 처리 중...\n",
      "랜드마크 인식 성공 이미지 수: 183/500\n",
      "[test/open] 500장 처리 중...\n",
      "랜드마크 인식 성공 이미지 수: 264/500\n",
      "[test/closed] 500장 처리 중...\n",
      "랜드마크 인식 성공 이미지 수: 271/500\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Mediapipe 설정\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    static_image_mode=True,\n",
    "    refine_landmarks=True,\n",
    "    max_num_faces=1,\n",
    "    min_detection_confidence=0.5\n",
    ")\n",
    "\n",
    "# 눈 감김 판단 함수 (왼/오 자동 감지)\n",
    "def is_eye_closed_by_landmark(landmarks, image_height, threshold=3):\n",
    "    try:\n",
    "        l_top = landmarks[386].y * image_height\n",
    "        l_bottom = landmarks[374].y * image_height\n",
    "        if abs(l_top - l_bottom) < threshold:\n",
    "            return True\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        r_top = landmarks[159].y * image_height\n",
    "        r_bottom = landmarks[145].y * image_height\n",
    "        if abs(r_top - r_bottom) < threshold:\n",
    "            return True\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return True  # 둘 다 감지 실패 시 감은 것으로 간주\n",
    "\n",
    "# 데이터셋 경로\n",
    "base_dir = r\"C:\\Users\\Users\\open-closed-eyes-dataset\"\n",
    "sets = ['train', 'val', 'test']\n",
    "labels = ['open', 'closed']\n",
    "max_images = 500\n",
    "landmark_detected = 0\n",
    "\n",
    "results = []\n",
    "\n",
    "for subset in sets:\n",
    "    for label in labels:\n",
    "        folder = os.path.join(base_dir, subset, label)\n",
    "        images = [f for f in os.listdir(folder) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        images = random.sample(images, min(max_images, len(images)))\n",
    "\n",
    "        print(f\"[{subset}/{label}] {len(images)}장 처리 중...\")\n",
    "\n",
    "        for img_name in images:\n",
    "            path = os.path.join(folder, img_name)\n",
    "            img = cv2.imread(path)\n",
    "            if img is None:\n",
    "                continue\n",
    "\n",
    "            ih, iw, _ = img.shape\n",
    "            rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            result = face_mesh.process(rgb)\n",
    "\n",
    "            if result.multi_face_landmarks:\n",
    "                landmark_detected += 1\n",
    "\n",
    "            pred = \"closed\"  # 기본값은 감은 상태\n",
    "\n",
    "            if result.multi_face_landmarks:\n",
    "                landmarks = result.multi_face_landmarks[0].landmark\n",
    "                closed = is_eye_closed_by_landmark(landmarks, ih)\n",
    "                pred = \"closed\" if closed else \"open\"\n",
    "\n",
    "            results.append({\n",
    "                'path': path,\n",
    "                'true_label': label,\n",
    "                'pred_label': pred\n",
    "            })\n",
    "        print(f\"랜드마크 인식 성공 이미지 수: {landmark_detected}/{len(images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "75db2f82-858c-4c04-82f9-b30e1401afce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 총 이미지: 3000 / 정확히 맞춘 수: 1500 / 정확도: 50.00%\n"
     ]
    }
   ],
   "source": [
    "total = len(results)\n",
    "correct = sum(1 for r in results if r['true_label'] == r['pred_label'])\n",
    "accuracy = (correct / total) * 100 if total > 0 else 0\n",
    "\n",
    "print(f\"\\n📊 총 이미지: {total} / 정확히 맞춘 수: {correct} / 정확도: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "31f7263d-2be0-4c23-b46c-45485fc08456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 분포: Counter({'closed': 3000})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "preds = [r['pred_label'] for r in results]\n",
    "counts = Counter(preds)\n",
    "print(\"예측 분포:\", counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9551c699-cbc1-42f9-ab4c-d139f8a0c530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 샘플 수: 408 / 검증: 367 / 테스트: 417\n",
      "✅ 학습 시작\n",
      "[Epoch 1] Loss: 4.7005 | Val Accuracy: 88.28%\n",
      "[Epoch 2] Loss: 4.3445 | Val Accuracy: 88.28%\n",
      "[Epoch 3] Loss: 4.2970 | Val Accuracy: 88.28%\n",
      "[Epoch 4] Loss: 4.2975 | Val Accuracy: 88.28%\n",
      "[Epoch 5] Loss: 4.3282 | Val Accuracy: 88.28%\n",
      "[Epoch 6] Loss: 4.3261 | Val Accuracy: 88.28%\n",
      "[Epoch 7] Loss: 4.3805 | Val Accuracy: 88.28%\n",
      "[Epoch 8] Loss: 4.2957 | Val Accuracy: 88.28%\n",
      "[Epoch 9] Loss: 4.2979 | Val Accuracy: 88.28%\n",
      "[Epoch 10] Loss: 4.3622 | Val Accuracy: 88.28%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "MAX_PER_CLASS = 2000\n",
    "\n",
    "# -------------------------\n",
    "# [1] Mediapipe landmark 추출\n",
    "# -------------------------\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, refine_landmarks=True)\n",
    "\n",
    "def extract_eye_landmarks(image):\n",
    "    ih, iw, _ = image.shape\n",
    "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    result = face_mesh.process(rgb)\n",
    "\n",
    "    if not result.multi_face_landmarks:\n",
    "        return None  # 얼굴 인식 실패\n",
    "\n",
    "    landmarks = result.multi_face_landmarks[0].landmark\n",
    "    try:\n",
    "        left_top = landmarks[386].y * ih\n",
    "        left_bottom = landmarks[374].y * ih\n",
    "        right_top = landmarks[159].y * ih\n",
    "        right_bottom = landmarks[145].y * ih\n",
    "        return [left_top, left_bottom, right_top, right_bottom]\n",
    "    except:\n",
    "        return None  # 좌표 추출 실패\n",
    "\n",
    "# -------------------------\n",
    "# [2] 이미지 경로 순회 및 좌표 수집\n",
    "# -------------------------\n",
    "def load_eye_data(base_dir, max_per_class=2000):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for label_name in ['open', 'closed']:\n",
    "        folder = os.path.join(base_dir, label_name)\n",
    "        files = [f for f in os.listdir(folder) if f.lower().endswith(('.jpg', '.png'))]\n",
    "        files = random.sample(files, min(max_per_class, len(files)))\n",
    "\n",
    "        label = 1 if label_name == 'open' else 0\n",
    "\n",
    "        for file in files:\n",
    "            path = os.path.join(folder, file)\n",
    "            img = cv2.imread(path)\n",
    "            if img is None:\n",
    "                continue\n",
    "\n",
    "            coords = extract_eye_landmarks(img)\n",
    "            if coords:\n",
    "                X.append(coords)\n",
    "                y.append(label)\n",
    "\n",
    "    return np.array(X, dtype=np.float32), np.array(y, dtype=np.int64)\n",
    "\n",
    "# -------------------------\n",
    "# [3] PyTorch Dataset 클래스\n",
    "# -------------------------\n",
    "class EyeLandmarkDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# -------------------------\n",
    "# [4] MLP 모델 정의\n",
    "# -------------------------\n",
    "class EyeMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(4, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# -------------------------\n",
    "# [5] 데이터 경로 설정 (train/val/test 폴더 각각 MAX_PER_CLASS개씩)\n",
    "# -------------------------\n",
    "train_dir = r\"C:\\Users\\Users\\open-closed-eyes-dataset\\train\"\n",
    "val_dir = r\"C:\\Users\\Users\\open-closed-eyes-dataset\\val\"\n",
    "test_dir = r\"C:\\Users\\Users\\open-closed-eyes-dataset\\test\"\n",
    "\n",
    "X_train, y_train = load_eye_data(train_dir, max_per_class=MAX_PER_CLASS)\n",
    "X_val, y_val = load_eye_data(val_dir, max_per_class=MAX_PER_CLASS)\n",
    "X_test, y_test = load_eye_data(test_dir, max_per_class=MAX_PER_CLASS)\n",
    "\n",
    "print(f\"학습 샘플 수: {len(X_train)} / 검증: {len(X_val)} / 테스트: {len(X_test)}\")\n",
    "\n",
    "# -------------------------\n",
    "# [6] Dataset/DataLoader\n",
    "# -------------------------\n",
    "train_loader = DataLoader(EyeLandmarkDataset(X_train, y_train), batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(EyeLandmarkDataset(X_val, y_val), batch_size=32)\n",
    "test_loader = DataLoader(EyeLandmarkDataset(X_test, y_test), batch_size=32)\n",
    "\n",
    "# -------------------------\n",
    "# [7] 모델 학습\n",
    "# -------------------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = EyeMLP().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(\"✅ 학습 시작\")\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # 검증\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            preds = model(X_batch).argmax(dim=1)\n",
    "            correct += (preds == y_batch).sum().item()\n",
    "            total += len(y_batch)\n",
    "\n",
    "    val_acc = correct / total * 100\n",
    "    print(f\"[Epoch {epoch+1}] Loss: {running_loss:.4f} | Val Accuracy: {val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1040e815-ae2c-4180-b2af-ebd1126e0e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 테스트 데이터셋 평가\n",
      "🎯 테스트 정확도: 96.95%\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# [8] 테스트 평가\n",
    "# -------------------------\n",
    "print(\"\\n✅ 테스트 데이터셋 평가\")\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        preds = model(X_batch).argmax(dim=1)\n",
    "        correct += (preds == y_batch).sum().item()\n",
    "        total += len(y_batch)\n",
    "\n",
    "test_acc = correct / total * 100\n",
    "print(f\"🎯 테스트 정확도: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "112dffad-fd01-47d6-aca0-fbcb019a799c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# -----------------------\n",
    "# [1] 하이퍼파라미터\n",
    "# -----------------------\n",
    "IMG_SIZE = 90\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# -----------------------\n",
    "# [2] 전처리 정의\n",
    "# -----------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "# -----------------------\n",
    "# [3] 랜덤 500개 추출 Dataset 클래스\n",
    "# -----------------------\n",
    "class CustomEyeDataset(Dataset):\n",
    "    def __init__(self, root_dir, max_per_class=2000, transform=None):\n",
    "        self.samples = []\n",
    "        self.transform = transform\n",
    "        classes = ['open', 'closed']\n",
    "\n",
    "        for label, cls in enumerate(classes):\n",
    "            folder = os.path.join(root_dir, cls)\n",
    "            files = [f for f in os.listdir(folder) if f.lower().endswith(('.jpg', '.png'))]\n",
    "            random.shuffle(files)\n",
    "            files = files[:max_per_class]\n",
    "\n",
    "            for fname in files:\n",
    "                self.samples.append((os.path.join(folder, fname), label))\n",
    "\n",
    "        random.shuffle(self.samples)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# -----------------------\n",
    "# [4] 데이터셋 로더\n",
    "# -----------------------\n",
    "train_dir = r\"C:\\Users\\Users\\open-closed-eyes-dataset\\train\"\n",
    "val_dir   = r\"C:\\Users\\Users\\open-closed-eyes-dataset\\val\"\n",
    "test_dir  = r\"C:\\Users\\Users\\open-closed-eyes-dataset\\test\"\n",
    "\n",
    "train_loader = DataLoader(CustomEyeDataset(train_dir, transform=transform), batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader(CustomEyeDataset(val_dir, transform=transform), batch_size=BATCH_SIZE)\n",
    "test_loader  = DataLoader(CustomEyeDataset(test_dir, transform=transform), batch_size=BATCH_SIZE)\n",
    "\n",
    "# -----------------------\n",
    "# [5] CNN 모델 정의\n",
    "# -----------------------\n",
    "class EyeCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(16, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 11 * 11, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model = EyeCNN().to(device)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "62d99a3b-57cd-4625-ba34-f389ea62c36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 테스트 정확도: 96.95%\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 6. 테스트 평가\n",
    "# ---------------------------\n",
    "def evaluate(loader):\n",
    "    model.eval()  # 평가 모드 전환\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            outputs = model(X)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    return correct / total * 100\n",
    "    \n",
    "test_acc = evaluate(test_loader)\n",
    "print(f\"\\n🎯 테스트 정확도: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fa617ebd-c4ac-48d5-95d6-f0a9ca834ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 샘플 수: 339 / 검증: 325 / 테스트: 288\n",
      "✅ 학습 시작\n",
      "[Epoch 1] Loss: 4.3233 | Val Accuracy: 92.92%\n",
      "[Epoch 2] Loss: 4.2116 | Val Accuracy: 92.92%\n",
      "[Epoch 3] Loss: 4.2671 | Val Accuracy: 92.92%\n",
      "[Epoch 4] Loss: 4.1870 | Val Accuracy: 92.92%\n",
      "[Epoch 5] Loss: 4.3676 | Val Accuracy: 92.92%\n",
      "[Epoch 6] Loss: 4.1704 | Val Accuracy: 92.92%\n",
      "[Epoch 7] Loss: 4.6892 | Val Accuracy: 92.92%\n",
      "[Epoch 8] Loss: 4.2520 | Val Accuracy: 92.92%\n",
      "[Epoch 9] Loss: 4.2774 | Val Accuracy: 92.92%\n",
      "[Epoch 10] Loss: 4.2715 | Val Accuracy: 92.92%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "MAX_PER_CLASS = 1666\n",
    "\n",
    "# -------------------------\n",
    "# [1] Mediapipe landmark 추출 (한쪽 눈만)\n",
    "# -------------------------\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, refine_landmarks=True)\n",
    "\n",
    "def extract_one_eye_landmarks(image):\n",
    "    ih, iw, _ = image.shape\n",
    "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    result = face_mesh.process(rgb)\n",
    "\n",
    "    if not result.multi_face_landmarks:\n",
    "        return None  # 얼굴 인식 실패\n",
    "\n",
    "    landmarks = result.multi_face_landmarks[0].landmark\n",
    "    try:\n",
    "        # 오른쪽 눈 위, 아래 좌표만 사용 (예: 159(위), 145(아래))\n",
    "        top = landmarks[159].y * ih\n",
    "        bottom = landmarks[145].y * ih\n",
    "        return [top, bottom]\n",
    "    except:\n",
    "        return None  # 좌표 추출 실패\n",
    "\n",
    "# -------------------------\n",
    "# [2] 이미지 경로 순회 및 좌표 수집\n",
    "# -------------------------\n",
    "def load_eye_data(base_dir, max_per_class=MAX_PER_CLASS):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for label_name in ['open', 'closed']:\n",
    "        folder = os.path.join(base_dir, label_name)\n",
    "        files = [f for f in os.listdir(folder) if f.lower().endswith(('.jpg', '.png'))]\n",
    "        files = random.sample(files, min(max_per_class, len(files)))\n",
    "\n",
    "        label = 1 if label_name == 'open' else 0\n",
    "\n",
    "        for file in files:\n",
    "            path = os.path.join(folder, file)\n",
    "            img = cv2.imread(path)\n",
    "            if img is None:\n",
    "                continue\n",
    "\n",
    "            coords = extract_one_eye_landmarks(img)\n",
    "            if coords:\n",
    "                X.append(coords)\n",
    "                y.append(label)\n",
    "\n",
    "    return np.array(X, dtype=np.float32), np.array(y, dtype=np.int64)\n",
    "\n",
    "# -------------------------\n",
    "# [3] PyTorch Dataset 클래스\n",
    "# -------------------------\n",
    "class EyeLandmarkDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# -------------------------\n",
    "# [4] MLP 모델 정의 (입력 노드 2개로 변경)\n",
    "# -------------------------\n",
    "class EyeMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(2, 32),   # 입력 노드 2개 -> 은닉층 32개 노드\n",
    "            nn.ReLU(),          # 비선형 활성화 함수 ReLU\n",
    "            nn.Linear(32, 16),  # 은닉층 32개 -> 은닉층 16개\n",
    "            nn.ReLU(),          # ReLU 활성화\n",
    "            nn.Linear(16, 2)    # 은닉층 16개 -> 출력층 2개 (open/closed 분류)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# -------------------------\n",
    "# [5] 데이터 경로 설정 및 데이터 로딩\n",
    "# -------------------------\n",
    "train_dir = r\"C:\\Users\\Users\\open-closed-eyes-dataset\\train\"\n",
    "val_dir = r\"C:\\Users\\Users\\open-closed-eyes-dataset\\val\"\n",
    "test_dir = r\"C:\\Users\\Users\\open-closed-eyes-dataset\\test\"\n",
    "\n",
    "X_train, y_train = load_eye_data(train_dir, max_per_class=MAX_PER_CLASS)\n",
    "X_val, y_val = load_eye_data(val_dir, max_per_class=MAX_PER_CLASS)\n",
    "X_test, y_test = load_eye_data(test_dir, max_per_class=MAX_PER_CLASS)\n",
    "\n",
    "print(f\"학습 샘플 수: {len(X_train)} / 검증: {len(X_val)} / 테스트: {len(X_test)}\")\n",
    "\n",
    "# -------------------------\n",
    "# [6] Dataset/DataLoader 생성\n",
    "# -------------------------\n",
    "train_loader = DataLoader(EyeLandmarkDataset(X_train, y_train), batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(EyeLandmarkDataset(X_val, y_val), batch_size=32)\n",
    "test_loader = DataLoader(EyeLandmarkDataset(X_test, y_test), batch_size=32)\n",
    "\n",
    "# -------------------------\n",
    "# [7] 모델 학습\n",
    "# -------------------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = EyeMLP().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(\"✅ 학습 시작\")\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            preds = model(X_batch).argmax(dim=1)\n",
    "            correct += (preds == y_batch).sum().item()\n",
    "            total += len(y_batch)\n",
    "\n",
    "    val_acc = correct / total * 100\n",
    "    print(f\"[Epoch {epoch+1}] Loss: {running_loss:.4f} | Val Accuracy: {val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "08a364d4-6344-4770-a951-51311d31786a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 테스트 데이터셋 평가\n",
      "🎯 테스트 정확도: 89.58%\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# [8] 테스트 평가\n",
    "# -------------------------\n",
    "print(\"\\n✅ 테스트 데이터셋 평가\")\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        preds = model(X_batch).argmax(dim=1)\n",
    "        correct += (preds == y_batch).sum().item()\n",
    "        total += len(y_batch)\n",
    "\n",
    "test_acc = correct / total * 100\n",
    "print(f\"🎯 테스트 정확도: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3d22ac02-30df-4378-b81d-78fec924f986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 파일 개수: 6665\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# test - closed 1666개\n",
    "# test - open 5325개\n",
    "# train - closed 33322개\n",
    "# train - open 106482개\n",
    "# val - closed 6665 개\n",
    "# val - open 21296 개\n",
    "folder_path = r\"C:\\Users\\Users\\open-closed-eyes-dataset\\val\\closed\"\n",
    "\n",
    "# 이미지 확장자 리스트\n",
    "image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.gif')\n",
    "\n",
    "files = [f for f in os.listdir(folder_path) if f.lower().endswith(image_extensions)]\n",
    "print(f\"이미지 파일 개수: {len(files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3c681bc0-d48b-47e9-910d-966f96088881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 샘플 수: 3332 / 검증: 3332 / 테스트: 3332\n",
      "Train Accuracy: 50.00%\n",
      "Validation Accuracy: 50.00%\n",
      "Test Accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "MAX_PER_CLASS = 1666\n",
    "\n",
    "# -------------------------\n",
    "# [1] 눈 영역에서 위, 아래 y 좌표 추출 (얼굴 인식 제거)\n",
    "# -------------------------\n",
    "def extract_one_eye_landmarks_direct(image):\n",
    "    ih, iw, _ = image.shape\n",
    "\n",
    "    # 눈 영역만 있다고 가정, 이미지 높이를 3등분하여 위, 아래 좌표 추출 예시\n",
    "    top = ih * 1/3\n",
    "    bottom = ih * 2/3\n",
    "    return [top, bottom]\n",
    "\n",
    "# -------------------------\n",
    "# [2] 이미지 경로 순회 및 좌표 수집\n",
    "# -------------------------\n",
    "def load_eye_data(base_dir, max_per_class=MAX_PER_CLASS):\n",
    "    data = []\n",
    "\n",
    "    for label_name in ['open', 'closed']:\n",
    "        folder = os.path.join(base_dir, label_name)\n",
    "        files = [f for f in os.listdir(folder) if f.lower().endswith(('.jpg', '.png'))]\n",
    "        files = random.sample(files, min(max_per_class, len(files)))\n",
    "\n",
    "        label = 1 if label_name == 'open' else 0\n",
    "\n",
    "        for file in files:\n",
    "            path = os.path.join(folder, file)\n",
    "            img = cv2.imread(path)\n",
    "            if img is None:\n",
    "                continue\n",
    "\n",
    "            coords = extract_one_eye_landmarks_direct(img)\n",
    "            if coords:\n",
    "                top, bottom = coords\n",
    "                distance = bottom - top\n",
    "                data.append((distance, label))\n",
    "\n",
    "    return data\n",
    "\n",
    "# -------------------------\n",
    "# [3] 간단한 임계값 기반 분류\n",
    "# -------------------------\n",
    "def simple_threshold_classifier(data, threshold):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for distance, label in data:\n",
    "        pred = 0 if distance < threshold else 1  # 거리 작으면 감김(closed=0), 크면 뜸(open=1)\n",
    "        if pred == label:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "\n",
    "    accuracy = correct / total * 100\n",
    "    return accuracy\n",
    "\n",
    "# -------------------------\n",
    "# [4] 데이터 경로 설정 및 데이터 로딩\n",
    "# -------------------------\n",
    "train_dir = r\"C:\\Users\\Users\\open-closed-eyes-dataset\\train\"\n",
    "val_dir = r\"C:\\Users\\Users\\open-closed-eyes-dataset\\val\"\n",
    "test_dir = r\"C:\\Users\\Users\\open-closed-eyes-dataset\\test\"\n",
    "\n",
    "train_data = load_eye_data(train_dir)\n",
    "val_data = load_eye_data(val_dir)\n",
    "test_data = load_eye_data(test_dir)\n",
    "\n",
    "print(f\"학습 샘플 수: {len(train_data)} / 검증: {len(val_data)} / 테스트: {len(test_data)}\")\n",
    "\n",
    "# -------------------------\n",
    "# [5] 임계값 설정 (예: 경험적으로 정하거나 검증 데이터에서 탐색)\n",
    "# -------------------------\n",
    "threshold = 50  # 픽셀 단위 임의 값, 적절히 조정 필요\n",
    "\n",
    "# -------------------------\n",
    "# [6] 정확도 평가\n",
    "# -------------------------\n",
    "train_acc = simple_threshold_classifier(train_data, threshold)\n",
    "val_acc = simple_threshold_classifier(val_data, threshold)\n",
    "test_acc = simple_threshold_classifier(test_data, threshold)\n",
    "\n",
    "print(f\"Train Accuracy: {train_acc:.2f}%\")\n",
    "print(f\"Validation Accuracy: {val_acc:.2f}%\")\n",
    "print(f\"Test Accuracy: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7d51e898-7c3c-4d3d-8131-fe066e97812d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 샘플 수: 2766 / 검증: 2714 / 테스트: 2719\n",
      "Train Accuracy: 52.31%\n",
      "Validation Accuracy: 53.35%\n",
      "Test Accuracy: 53.51%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "MAX_PER_CLASS = 1666\n",
    "\n",
    "# -------------------------\n",
    "# [1] 눈 이미지에서 눈꺼풀 위·아래 y 좌표 직접 추출\n",
    "# -------------------------\n",
    "def extract_eye_top_bottom(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 눈동자는 보통 어두워서 역이진화 (어두운 영역을 흰색으로)\n",
    "    _, thresh = cv2.threshold(gray, 50, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # 수평 픽셀 합 (y축 방향)\n",
    "    horizontal_sum = np.sum(thresh, axis=1)\n",
    "\n",
    "    ys = np.where(horizontal_sum > 0)[0]\n",
    "\n",
    "    if len(ys) == 0:\n",
    "        return None\n",
    "\n",
    "    top = ys[0]\n",
    "    bottom = ys[-1]\n",
    "\n",
    "    return top, bottom\n",
    "\n",
    "# -------------------------\n",
    "# [2] 이미지 폴더 순회하며 데이터(눈꺼풀 거리, 라벨) 수집\n",
    "# -------------------------\n",
    "def load_eye_data(base_dir, max_per_class=MAX_PER_CLASS):\n",
    "    data = []\n",
    "\n",
    "    for label_name in ['open', 'closed']:\n",
    "        folder = os.path.join(base_dir, label_name)\n",
    "        files = [f for f in os.listdir(folder) if f.lower().endswith(('.jpg', '.png'))]\n",
    "        files = random.sample(files, min(max_per_class, len(files)))\n",
    "\n",
    "        label = 1 if label_name == 'open' else 0\n",
    "\n",
    "        for file in files:\n",
    "            path = os.path.join(folder, file)\n",
    "            img = cv2.imread(path)\n",
    "            if img is None:\n",
    "                continue\n",
    "\n",
    "            coords = extract_eye_top_bottom(img)\n",
    "            if coords:\n",
    "                top, bottom = coords\n",
    "                distance = bottom - top\n",
    "                data.append((distance, label))\n",
    "\n",
    "    return data\n",
    "\n",
    "# -------------------------\n",
    "# [3] 임계값 기반 눈 감김 분류기\n",
    "# -------------------------\n",
    "def simple_threshold_classifier(data, threshold):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for distance, label in data:\n",
    "        pred = 0 if distance < threshold else 1\n",
    "        if pred == label:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "\n",
    "    accuracy = correct / total * 100 if total > 0 else 0\n",
    "    return accuracy\n",
    "\n",
    "# -------------------------\n",
    "# [4] 데이터 경로 설정 및 데이터 로딩\n",
    "# -------------------------\n",
    "train_dir = r\"C:\\Users\\Users\\open-closed-eyes-dataset\\train\"\n",
    "val_dir = r\"C:\\Users\\Users\\open-closed-eyes-dataset\\val\"\n",
    "test_dir = r\"C:\\Users\\Users\\open-closed-eyes-dataset\\test\"\n",
    "\n",
    "train_data = load_eye_data(train_dir)\n",
    "val_data = load_eye_data(val_dir)\n",
    "test_data = load_eye_data(test_dir)\n",
    "\n",
    "print(f\"학습 샘플 수: {len(train_data)} / 검증: {len(val_data)} / 테스트: {len(test_data)}\")\n",
    "\n",
    "# -------------------------\n",
    "# [5] 경험적으로 정한 임계값 (픽셀 단위, 눈 이미지 크기에 따라 조정 필요)\n",
    "# -------------------------\n",
    "threshold = 15\n",
    "\n",
    "# -------------------------\n",
    "# [6] 정확도 평가\n",
    "# -------------------------\n",
    "train_acc = simple_threshold_classifier(train_data, threshold)\n",
    "val_acc = simple_threshold_classifier(val_data, threshold)\n",
    "test_acc = simple_threshold_classifier(test_data, threshold)\n",
    "\n",
    "print(f\"Train Accuracy: {train_acc:.2f}%\")\n",
    "print(f\"Validation Accuracy: {val_acc:.2f}%\")\n",
    "print(f\"Test Accuracy: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676d21a1-c22d-47b3-b7fe-ce573239638b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
