import os
import random
import numpy as np
import torch
import torch.nn as nn
import torchvision.transforms as transforms
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader, Subset

# -------------------------
# [1] ì„¤ì •
# -------------------------
BATCH_SIZE = 64
EPOCHS = 10
LR = 0.0039
IMG_SIZE = 90
MAX_PER_CLASS_test = 500
MAX_PER_CLASS_val = 500
MAX_PER_CLASS_train = 500

train_dir = r"C:\Users\Users\open-closed-eyes-dataset\train"
val_dir   = r"C:\Users\Users\open-closed-eyes-dataset\val"
test_dir  = r"C:\Users\Users\open-closed-eyes-dataset\test"

# -------------------------
# [2] ì „ì²˜ë¦¬ ì •ì˜
# -------------------------
transform = transforms.Compose([
    #transforms.Grayscale(),
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

# -------------------------
# [3] í´ë˜ìŠ¤ë³„ ê· í˜• ìƒ˜í”Œë§ í•¨ìˆ˜
# -------------------------
def balanced_subset(dataset, max_per_class):
    targets = np.array(dataset.targets)
    indices = []
    for class_idx in range(len(dataset.classes)):
        class_indices = np.where(targets == class_idx)[0]
        sampled = random.sample(list(class_indices), min(len(class_indices), max_per_class))
        indices.extend(sampled)
    return Subset(dataset, indices)

# -------------------------
# [4] ë°ì´í„°ì…‹ ë° ë¡œë” ìƒì„±
# -------------------------
train_dataset = balanced_subset(ImageFolder(train_dir, transform=transform), MAX_PER_CLASS_train)
val_dataset   = balanced_subset(ImageFolder(val_dir, transform=transform), MAX_PER_CLASS_val)
test_dataset  = balanced_subset(ImageFolder(test_dir, transform=transform), MAX_PER_CLASS_test)

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)
test_loader  = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)

# -------------------------
# [5] CNN ëª¨ë¸ ì •ì˜ (Sigmoid ì¶œë ¥)
# -------------------------
class EyeCNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(3, 16, 3, padding=1),  # 90x90 -> 90x90
            nn.ReLU(),
            nn.MaxPool2d(2),                 # 90x90 -> 45x45

            nn.Conv2d(16, 32, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),                 # 45x45 -> 22x22

            nn.Conv2d(32, 64, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),                 # 22x22 -> 11x11

            nn.Conv2d(64, 128, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),                 # 11x11 -> 5x5
        )

        self.fc = nn.Sequential(
            nn.Flatten(),
            nn.Linear(128 * 5 * 5, 128),
            nn.ReLU(),
            nn.Linear(128, 1),       # ì´ì§„ ë¶„ë¥˜: í•˜ë‚˜ì˜ ê°’
            nn.Sigmoid()             # í™•ë¥ ê°’ ì¶œë ¥
        )

    def forward(self, x):
        return self.fc(self.conv(x))

# -------------------------
# [6] í•™ìŠµ ì„¤ì •
# -------------------------
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = EyeCNN().to(device)
criterion = nn.BCELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=LR)

# -------------------------
# [7] í•™ìŠµ ë£¨í”„
# -------------------------
print("âœ… í•™ìŠµ ì‹œì‘")
print(f"ğŸ“Š Train í´ë˜ìŠ¤ ë¶„í¬: {[train_dataset.dataset.classes[i] for i in np.unique(train_dataset.dataset.targets)]}")
print(f"Train ìƒ˜í”Œ ìˆ˜: {len(train_dataset)}")
print(f"Val ìƒ˜í”Œ ìˆ˜: {len(val_dataset)}")
print(f"Test ìƒ˜í”Œ ìˆ˜: {len(test_dataset)}")

for epoch in range(EPOCHS):
    model.train()
    running_loss = 0
    for imgs, labels in train_loader:
        imgs = imgs.to(device)
        labels = labels.float().unsqueeze(1).to(device)  # [batch_size, 1]

        optimizer.zero_grad()
        outputs = model(imgs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()

    # ê²€ì¦ ì •í™•ë„ ê³„ì‚°
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for imgs, labels in val_loader:
            imgs = imgs.to(device)
            labels = labels.to(device)
            outputs = model(imgs)
            preds = (outputs > 0.5).int().squeeze()
            correct += (preds == labels).sum().item()
            total += len(labels)

    val_acc = correct / total * 100
    print(f"[Epoch {epoch+1}] Loss: {running_loss:.4f} | Val Accuracy: {val_acc:.2f}%")

# -------------------------
# [8] í…ŒìŠ¤íŠ¸ ì •í™•ë„
# -------------------------
model.eval()
correct = 0
total = 0
with torch.no_grad():
    for imgs, labels in test_loader:
        imgs = imgs.to(device)
        labels = labels.to(device)
        outputs = model(imgs)
        preds = (outputs > 0.5).int().squeeze()
        correct += (preds == labels).sum().item()
        total += len(labels)

test_acc = correct / total * 100
print(f"ğŸ§ª í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_acc:.2f}%")
