{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37bc152-af0c-4c42-84a8-d5e0588881d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë”¥ëŸ¬ë‹ CNNê¸°ë²•ìœ¼ë¡œ ì ìš©í•œ ëª¨ë¸\n",
    "# ê²°ê³¼ê°’ ì¶œë ¥ì´ ë‹¤ìŒê³¼ ê°™ì´ ë‚˜ì˜´\n",
    "#âœ… í•™ìŠµ ì‹œì‘\n",
    "#[Epoch 1] Loss: 34.5591 | Val Accuracy: 89.26%\n",
    "#[Epoch 2] Loss: 25.4763 | Val Accuracy: 90.88%\n",
    "#[Epoch 3] Loss: 22.5501 | Val Accuracy: 90.94%\n",
    "#[Epoch 4] Loss: 19.6723 | Val Accuracy: 91.90%\n",
    "#[Epoch 5] Loss: 17.4573 | Val Accuracy: 93.25%\n",
    "#[Epoch 6] Loss: 15.0400 | Val Accuracy: 93.49%\n",
    "#[Epoch 7] Loss: 12.1350 | Val Accuracy: 93.16%\n",
    "#[Epoch 8] Loss: 9.8619 | Val Accuracy: 94.15%\n",
    "#[Epoch 9] Loss: 7.9755 | Val Accuracy: 93.55%\n",
    "#[Epoch 10] Loss: 6.6986 | Val Accuracy: 93.16%\n",
    "#ğŸ§ª í…ŒìŠ¤íŠ¸ ì •í™•ë„: 93.34%\n",
    "# ê½¤ ë†’ì€ ì •í™•ë„, êµìœ¡ì—ì„œ ë°°ìš´ epochë¥¼ ì¡°ì ˆí•´ì„œ êµìœ¡í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì´ìš©í•  ìˆ˜ ìˆìŒ\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "# -------------------------\n",
    "# [1] ì„¤ì •\n",
    "# -------------------------\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "LR = 0.001\n",
    "IMG_SIZE = 90\n",
    "MAX_PER_CLASS = 1666  # í´ë˜ìŠ¤ë‹¹ ìƒ˜í”Œ ìˆ˜\n",
    "\n",
    "train_dir = r\"C:\\Users\\Users\\open-closed-eyes-dataset\\train\"\n",
    "val_dir   = r\"C:\\Users\\Users\\open-closed-eyes-dataset\\val\"\n",
    "test_dir  = r\"C:\\Users\\Users\\open-closed-eyes-dataset\\test\"\n",
    "\n",
    "# -------------------------\n",
    "# [2] ì „ì²˜ë¦¬ ì •ì˜\n",
    "# -------------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# -------------------------\n",
    "# [3] í´ë˜ìŠ¤ë³„ ê· í˜• ìƒ˜í”Œë§ í•¨ìˆ˜\n",
    "# -------------------------\n",
    "def balanced_subset(dataset, max_per_class):\n",
    "    targets = np.array(dataset.targets)\n",
    "    indices = []\n",
    "\n",
    "    for class_idx in range(len(dataset.classes)):\n",
    "        class_indices = np.where(targets == class_idx)[0]\n",
    "        sampled = random.sample(list(class_indices), min(len(class_indices), max_per_class))\n",
    "        indices.extend(sampled)\n",
    "\n",
    "    return Subset(dataset, indices)\n",
    "\n",
    "# -------------------------\n",
    "# [4] ë°ì´í„°ì…‹ ë° ë¡œë” ìƒì„±\n",
    "# -------------------------\n",
    "train_dataset = balanced_subset(ImageFolder(train_dir, transform=transform), MAX_PER_CLASS)\n",
    "val_dataset   = balanced_subset(ImageFolder(val_dir, transform=transform), MAX_PER_CLASS)\n",
    "test_dataset  = balanced_subset(ImageFolder(test_dir, transform=transform), MAX_PER_CLASS)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# -------------------------\n",
    "# [5] CNN ëª¨ë¸ ì •ì˜\n",
    "# -------------------------\n",
    "class EyeCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, padding=1),  # 90x90 -> 90x90\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),                 # 90x90 -> 45x45\n",
    "\n",
    "            nn.Conv2d(16, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),                 # 45x45 -> 22x22\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),                 # 22x22 -> 11x11\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 11 * 11, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 2)  # 2 classes: open/closed\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# -------------------------\n",
    "# [6] í•™ìŠµ ì„¤ì •\n",
    "# -------------------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = EyeCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# -------------------------\n",
    "# [7] í•™ìŠµ ë£¨í”„\n",
    "# -------------------------\n",
    "print(\"âœ… í•™ìŠµ ì‹œì‘\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # ê²€ì¦ ì •í™•ë„\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            preds = model(imgs).argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += len(labels)\n",
    "\n",
    "    val_acc = correct / total * 100\n",
    "    print(f\"[Epoch {epoch+1}] Loss: {running_loss:.4f} | Val Accuracy: {val_acc:.2f}%\")\n",
    "\n",
    "# -------------------------\n",
    "# [8] í…ŒìŠ¤íŠ¸ ì •í™•ë„\n",
    "# -------------------------\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        preds = model(imgs).argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += len(labels)\n",
    "\n",
    "test_acc = correct / total * 100\n",
    "print(f\"ğŸ§ª í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_acc:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
